{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as fn\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".master(\"local\") \\\n",
    ".appName(\"cast_column_df\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [(\"James\",34,\"2006-01-01\",\"true\",\"M\",3000.60),\n",
    "    (\"Michael\",33,\"1980-01-10\",\"true\",\"F\",3300.80),\n",
    "    (\"Robert\",37,\"06-01-1992\",\"false\",\"M\",5000.50)\n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\",\"age\",\"jobStartDate\",\"isGraduated\",\"gender\",\"salary\"]\n",
    "df1 = spark.createDataFrame(data = simpleData, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------------+-----------+------+------+\n",
      "|firstname|age|jobStartDate|isGraduated|gender|salary|\n",
      "+---------+---+------------+-----------+------+------+\n",
      "|    James| 34|  2006-01-01|       true|     M|3000.6|\n",
      "|  Michael| 33|  1980-01-10|       true|     F|3300.8|\n",
      "|   Robert| 37|        null|      false|     M|5000.5|\n",
      "+---------+---+------------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn(\"age\",fn.col(\"age\").cast(StringType())) \\\n",
    ".withColumn(\"isGraduated\",fn.col(\"isGraduated\").cast(BooleanType())) \\\n",
    ".withColumn(\"jobStartDate\", fn.col(\"jobStartDate\").cast(DateType())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-----------+\n",
      "|age|jobStartdate|isGraduated|\n",
      "+---+------------+-----------+\n",
      "| 34|  2006-01-01|       true|\n",
      "| 33|  1980-01-10|       true|\n",
      "| 37|  06-01-1992|      false|\n",
      "+---+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column expression\n",
    "df3 = df1.selectExpr(\"cast(age as int) age\", \"cast(jobStartDate as string) jobStartdate\", \\\n",
    "                    \"cast(isGraduated as string) isGraduated\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------------+\n",
      "|age|isGraduated|jobStartDate|\n",
      "+---+-----------+------------+\n",
      "| 34|       true|  2006-01-01|\n",
      "| 33|       true|  1980-01-10|\n",
      "| 37|      false|        null|\n",
      "+---+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark sql\n",
    "df1.createOrReplaceTempView(\"castColumn\")\n",
    "spark.sql(\"select string(age) age, boolean(isGraduated) isGraduated, date(jobStartDate) jobStartDate from castColumn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
